<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
	<title>Portfolio - Jesse Mehami</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>
	<!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" /> -->
</head>

<body class="is-preload">

	<!-- Wrapper -->
	<div id="wrapper">

		<!-- Header -->
		<header id="header" class="alt">
			<span class="logo"><img src="images/logo.svg" alt="" /></span>
			<h1>Jesse Mehami</h1>
			<p>Robotics Computer Vision Engineer<br />
			</p>
			<ul class="icons">
				<li>
					<a href="https://www.linkedin.com/in/jessemehami" class="icon brands fa-linkedin alt">
						<span class="label">
							LinkedIn
						</span>
					</a>
				</li>
				<li>
					<a href="https://github.com/jmehami1" class="icon brands fa-github alt">
						<span class="label">
							GitHub
						</span>
					</a>
				</li>
			</ul>
		</header>

		<!-- Nav -->
		<nav id="nav">
			<ul>
				<li><a href="#about" class="active">About</a></li>
				<li><a href="#projects">Projects</a></li>
				<li><a href="#publications">Publications</a></li>
				<li><a href="#contact">Contact</a></li>
			</ul>
		</nav>

		<!-- Main -->
		<div id="main">

			<!-- Introduction -->
			<section id="about" class="main">
				<div class="spotlight">
					<div class="content">
						<header class="major">
							<h2>Ipsum sed adipiscing</h2>
						</header>
						<p>Sed lorem ipsum dolor sit amet nullam consequat feugiat consequat magna
							adipiscing magna etiam amet veroeros. Lorem ipsum dolor tempus sit cursus.
							Tempus nisl et nullam lorem ipsum dolor sit amet aliquam.</p>
						<ul class="actions">
							<li><a href="generic.html" class="button">Learn More</a></li>
						</ul>
					</div>
					<span class="image"><img src="images/pic01.jpg" alt="" /></span>
				</div>
			</section>

			<!-- First Section -->
			<section id="projects" class="main special">
				<header class="major">
					<h2>Projects</h2>
					<script>
						function displayImagesFromFolderInRow(containerId) {
							// This function will load all images that are contained in a local file and add them as image attributes to the publication container.
							var container = document.getElementById(containerId);
							var folderPath = "https://api.github.com/repos/jmehami1/jmehami1.github.io/contents/images/projects/" + container.id;

							function isImageFile(fileName) {
								const imageExtensions = ['jpg', 'jpeg', 'png', 'gif'];
								const fileExtension = fileName.toLowerCase().split('.').pop();

								return imageExtensions.includes(fileExtension);
							}

							(async () => {
								const response = await fetch(folderPath);
								const data = await response.json();
								data.forEach(function (fileElement) {

									var filePath = fileElement.path;
									var fileDownloadUrl = fileElement.download_url;

									if (isImageFile(filePath)) {
										var img = new Image();
										img.src = fileDownloadUrl;
										img.alt = filePath;
										container.appendChild(img);
									}
								});
							})()
						}
					</script>
				</header>

				<div class="project">
					<h2>Hyperspectral Deep Learning of Subcutaneous Fat Depth</h2>
					<p>
						<u><strong>Summary</strong></u> I modelled the depth of subcutaneous fat (in millimeters) on
						lamb cuts using <a href="https://en.wikipedia.org/wiki/Hyperspectral_imaging"
							target="_blank">hyperspectral imaging</a> through training CNN deep learning models. The
						hyperspectral data was captured using a RGB-D and line-scan hyperspectral camera system where
						the ground-truth fat depth data was acquired from CT scans. Effects due to the 3D shape of the
						cuts and the illumination on their surfaces were first removed from the hyperspectral images,
						which were then used to estimate the material property of reflectance. The estimated reflectance
						was used to train the regression models. The distribution in fat depth was seen to be
						imbalanced.

						<br><br>

						<u><strong>Results</strong></u> The CNN was compared to a multi-layer perceptron (MLP) and
						linear regression models. The results for R2 and RMSE in Fat Depth are shown for all models in
						the table below. The CNN demonstrated the best fit in fat depth. The maximum fat depth that can
						be accurately estimated by hyperspectral camera was around 15mm.
					<table>
						<thead>
							<tr>
								<th>Model</th>
								<th>R2</th>
								<th>RMSE in Fat Depth (mm)</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Linear Regression</td>
								<td>0.65</td>
								<td>1.78</td>
							</tr>
							<tr>
								<td>MLP</td>
								<td>0.73</td>
								<td>1.57</td>
							</tr>
							<tr>
								<td><strong>CNN</strong></td>
								<td><strong>0.81</strong></td>
								<td><strong>1.17</strong></td>
							</tr>
						</tbody>
					</table>
					</p>
					<!-- <h3><a href="https://github.com/jmehami1/multicamera-calibration-ros"
							target="_blank"><strong>GitHub</strong></a></h3> -->

					<div class="imagerow" id="hyperspectral_deep_learning_fat_depth_top">
						<script>
							displayImagesFromFolderInRow("hyperspectral_deep_learning_fat_depth_top");
						</script>
					</div>
					<div class="imagerow" id="hyperspectral_deep_learning_fat_depth_bottom">
						<script>
							displayImagesFromFolderInRow("hyperspectral_deep_learning_fat_depth_bottom");
						</script>
					</div>
				</div>


				<div class="project">
					<h2>Multi-Camera Extrinsic Calibration in ROS</h2>
					<p>
						<u><strong>Summary</strong></u> I was required to extrinsically calibrate 16 RGB-D cameras with
						partial-overlapping views that were setup in a ROS environment.
						I solved the calibration by creating a double-sided <a
							href="https://docs.opencv.org/4.x/db/da9/tutorial_aruco_board_detection.html"
							target="_blank">ArUco
							board</a> and solved the optimization as a pose graph using <a
							href="https://github.com/RainerKuemmerle/g2o" target="_blank">g2o solver</a>.

						<br><br>

						<u><strong>Results</strong></u> Point cloud data from the cameras was used to create 3D
						reconstructed models. My calibration approach reduced the error in the models by a factor 10
						when compared the previous calibration method. The total calibration time, which includes
						collecting the data and solving the calibration problem, was reduced by over 90% when compared
						to the previous method that calibrated cameras pairwise.
					</p>
					<h3><a href="https://github.com/jmehami1/multicamera-calibration-ros"
							target="_blank"><strong>GitHub</strong></a></h3>

					<div class="imagerow" id="multi_camera_calibration_top">
						<script>
							displayImagesFromFolderInRow("multi_camera_calibration_top");
						</script>
					</div>
					<div class="imagerow" id="multi_camera_calibration_bottom">
						<script>
							displayImagesFromFolderInRow("multi_camera_calibration_bottom");
						</script>
					</div>
				</div>

				<div class="project">
					<h2>Line-scan Frame Camera Calibration</h2>
					<p>
						<u><strong>Summary</strong></u> I was required to calibrate a line-scan hyperspectral camera to
						use for robotic applications. The difficulty with calibrating this camera is the single spatial
						dimension. I successfully implemented the calibration by using an additional 2D color camera
						where the cameras were modelled according to the <a
							href="https://en.wikipedia.org/wiki/Pinhole_camera_model">pinhole
							camera model</a>. This calibration incorporated uncertainty
						estimation due to pixel noise, which was later used to create a novel active calibration
						algorithm (<a href="#pub_observability_line_scan_calibration">see below</a>).
						This work has since been updated to use OpenCV's <a
							href="https://docs.opencv.org/4.x/db/da9/tutorial_aruco_board_detection.html">ArUco
							board</a> for automatic pose estimation of the calibration board.

						<br><br>

						<u><strong>Results</strong></u> The calibration made it possible to reproject line-scan images
						to color images. The active calibration algorithm reduced the error in the calibration
						parameters by 26% while using fewer images when compared to a naive approach that used all
						images.
					</p>
					<h3><a href="https://github.com/jmehami1/Line-scan_Frame_Camera_Calibration"
							target="_blank"><strong>GitHub</strong></a></h3>

					<div class="imagerow" id="line_scan_frame_camera_calibration_top">
						<script>
							displayImagesFromFolderInRow("line_scan_frame_camera_calibration_top");
						</script>
					</div>
					<div class="imagerow" id="line_scan_frame_camera_calibration_bottom">
						<script>
							displayImagesFromFolderInRow("line_scan_frame_camera_calibration_bottom");
						</script>
					</div>
				</div>


				<!-- <ul class="features">
					<li>
						<span class="icon solid major style1 fa-code"></span>
						<h3>Ipsum consequat</h3>
						<p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed
							consequat.</p>
					</li>
					<li>
						<span class="icon major style3 fa-copy"></span>
						<h3>Amed sed feugiat</h3>
						<p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed
							consequat.</p>
					</li>
					<li>
						<span class="icon major style5 fa-gem"></span>
						<h3>Dolor nullam</h3>
						<p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed
							consequat.</p>
					</li>
				</ul> -->
				<footer class="major">
					<!-- <ul class="actions special">
						<li><a href="generic.html" class="button">Learn More</a></li>
					</ul> -->
				</footer>
			</section>

			<!-- Second Section -->
			<section id="publications" class="main special">
				<header class="major">
					<h2>Publications</h2>

					<script>
						function displayImagesFromFolderInRow(containerId) {
							// This function will load all images that are contained in a local file and add them as image attributes to the publication container.
							var container = document.getElementById(containerId);
							var folderPath = "https://api.github.com/repos/jmehami1/jmehami1.github.io/contents/images/publications/" + container.id;

							function isImageFile(fileName) {
								const imageExtensions = ['jpg', 'jpeg', 'png', 'gif'];
								const fileExtension = fileName.toLowerCase().split('.').pop();

								return imageExtensions.includes(fileExtension);
							}

							(async () => {
								const response = await fetch(folderPath);
								const data = await response.json();
								data.forEach(function (fileElement) {

									var filePath = fileElement.path;
									var fileDownloadUrl = fileElement.download_url;

									if (isImageFile(filePath)) {
										var img = new Image();
										img.src = fileDownloadUrl;
										img.alt = filePath;
										container.appendChild(img);
									}
								});
							})()
						}
					</script>
				</header>
				<!-- <ul class="statistics">
					<li class="style1">
						<span class="icon solid fa-code-branch"></span>
						<strong>5,120</strong> Etiam
					</li>
					<li class="style2">
						<span class="icon fa-folder-open"></span>
						<strong>8,192</strong> Magna
					</li>
					<li class="style3">
						<span class="icon solid fa-signal"></span>
						<strong>2,048</strong> Tempus
					</li>
					<li class="style4">
						<span class="icon solid fa-laptop"></span>
						<strong>4,096</strong> Aliquam
					</li>
					<li class="style5">
						<span class="icon fa-gem"></span>
						<strong>1,024</strong> Nullam
					</li>
				</ul> -->

				<div class="publication">
					<h2><a href="http://hdl.handle.net/10453/164273" target="_blank">Subcutaneous Fat Depth Regression
							Using Hyperspectral and
							Depth Imaging</a></h2>
					<p style="text-align: left;">
						This paper uses a calibrated line-scan hyperspectral and frame camera system with a calibrated
						light source to model the subcutaneous fat depth of lamb cut samples using machine learning. The
						ground-truth fat depth is acquired from ray-casting into CT scans of the lamb cut samples. These
						CT scans are first converted into 3D meshes, which then are aligned to a 3D reconstructed mesh
						from depth images. Finally, the fat depth is acquired through ray-casting hyperspectral pixels.
						Fat depth models are trained using classic and deep learning models, where the deep learning
						models show the best results.
					</p>
					<!-- <h3><a href="https://github.com/jmehami1/Line-scan_Frame_Camera_Calibration"
							target="_blank"><strong>GitHub</strong></a></h3> -->
					<div class="imagerow" id="subcutaneous_fat_depth_regression">
						<script>
							displayImagesFromFolderInRow("subcutaneous_fat_depth_regression");
						</script>
					</div>
				</div>

				<div class="publication">
					<h2><a href="https://doi.org/10.1109/LRA.2022.3192208" target="_blank">Multi-Modal Non-Isotropic
							Light Source Modelling for Reflectance Estimation in Hyperspectral Imaging</a></h2>
					<p style="text-align: left;">
						This paper improves the estimation of the material property of reflectance for an object of
						interest that is captured using a calibrated line-scan hyperspectral and frame camera system,
						by modeling a light source and incorporating shape information.
						The reflected light from the object of interest is assumed to be described by the dichromatic
						reflectance model. The cameras, light source and objects are all near-field
						where the incident irradiance varies over the object's surface. The light source modeling uses a
						Gaussian Process with a non-zero mean function to capture the spatial irradiance
						of an actual light source. The proposed reflectance estimation involves optimization that uses
						the irradiance estimated from the Gaussian Process model with additional terms that
						involve the surface shape.
					</p>
					<h3><a href="https://github.com/jmehami1/MMHS-RE" target="_blank"><strong>GitHub</strong></a></h3>

					<div class="imagerow" id="multi_modal_non-isotropic_light_source">
						<script>
							displayImagesFromFolderInRow("multi_modal_non-isotropic_light_source");
						</script>
					</div>
					<div class="imagerow" id="multi_modal_non-isotropic_reflectance">
						<script>
							displayImagesFromFolderInRow("multi_modal_non-isotropic_reflectance");
						</script>
					</div>

				</div>

				<div class="publication" id="pub_observability_line_scan_calibration">
					<h2><a href="https://doi.org/10.1109/MFI49285.2020.9235226" target="_blank">Observability driven
							multi-modal line-scan camera calibration</a></h2>
					<p style="text-align: left;">
						This paper improves the calibration of a line-scan camera through a novel active calibration
						algorithm. The line-scan camera is combined with a 2D traditional frame camera (color or RGB
						camera). The active calibration algorithm filters through the calibration dataset and only uses
						images that improve parameter estimation through calculation of the observability.
					</p>
					<h3><a href="https://github.com/jmehami1/Line-scan_Frame_Camera_Calibration"
							target="_blank"><strong>GitHub</strong></a></h3>
					<div class="imagerow" id="observability_line_scan_calibration">
						<script>
							displayImagesFromFolderInRow("observability_line_scan_calibration");
						</script>
					</div>
				</div>

				<footer class="major">
					<ul class="actions special">
						<li><a href="https://scholar.google.com/citations?user=j3bTQ84AAAAJ&hl=en&oi=ao" class="button"
								target="_blank">More Details</a></li>
					</ul>
				</footer>
			</section>

			<!-- Get Started -->
			<section id="contact" class="main special">
				<header class="major">
					<h2>Congue imperdiet</h2>
					<p>Donec imperdiet consequat consequat. Suspendisse feugiat congue<br />
						posuere. Nulla massa urna, fermentum eget quam aliquet.</p>
				</header>
				<footer class="major">
					<ul class="actions special">
						<li><a href="generic.html" class="button primary">Get Started</a></li>
						<li><a href="generic.html" class="button">Learn More</a></li>
					</ul>
				</footer>
			</section>

		</div>

		<!-- Footer -->
		<footer id="footer">
			<section>
				<h2>Aliquam sed mauris</h2>
				<p>Sed lorem ipsum dolor sit amet et nullam consequat feugiat consequat magna adipiscing tempus etiam
					dolore veroeros. eget dapibus mauris. Cras aliquet, nisl ut viverra sollicitudin, ligula erat
					egestas velit, vitae tincidunt odio.</p>
				<ul class="actions">
					<li><a href="generic.html" class="button">Learn More</a></li>
				</ul>
			</section>
			<section>
				<h2>Etiam feugiat</h2>
				<dl class="alt">
					<dt>Address</dt>
					<dd>1234 Somewhere Road &bull; Nashville, TN 00000 &bull; USA</dd>
					<dt>Phone</dt>
					<dd>(000) 000-0000 x 0000</dd>
					<dt>Email</dt>
					<dd><a href="#">information@untitled.tld</a></dd>
				</dl>
				<ul class="icons">
					<li>
						<a href="https://www.linkedin.com/in/jessemehami" class="icon brands fa-linkedin alt">
							<span class="label">
								LinkedIn
							</span>
						</a>
					</li>
					<li>
						<a href="https://github.com/jmehami1" class="icon brands fa-github alt">
							<span class="label">
								GitHub
							</span>
						</a>
					</li>
				</ul>
			</section>
			<p class="copyright">&copy; Untitled. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
		</footer>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>